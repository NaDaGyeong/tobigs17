{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fu39oBW0RVn5"
   },
   "source": [
    "# [과제 3] 로지스틱 회귀분석\n",
    "### - sklearn 패키지를 사용해 로지스틱 회귀분석을 진행해주세요.\n",
    "### - 성능지표를 계산하고 이에 대해 해석해주세요.\n",
    "### - 성능 개선을 시도해주세요. (어떠한 성능지표를 기준으로 개선을 시도했는지, 그 이유도 함께 적어주세요.)\n",
    "### - 주석으로 설명 및 근거 자세하게 달아주시면 감사하겠습니다. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rN2SWezRVn_"
   },
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7SYKNvQRVn_"
   },
   "source": [
    "출처 : https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "\n",
    "\n",
    "* V1 ~ V28 : 비식별화 된 개인정보 \n",
    "* **Class** : Target 변수  \n",
    "  - 1 : fraudulent transactions (사기)\n",
    "  - 0 : otherwise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Uvjw2fTCRVoA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "znQit70ZRVoA"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"assignment3_creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "id": "v98OeXW5RVoB",
    "outputId": "42afeddc-07e6-4224-95ee-08b455f72475"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.848212</td>\n",
       "      <td>2.384900</td>\n",
       "      <td>0.379573</td>\n",
       "      <td>1.048381</td>\n",
       "      <td>-0.845070</td>\n",
       "      <td>2.537837</td>\n",
       "      <td>-4.542983</td>\n",
       "      <td>-10.201458</td>\n",
       "      <td>-1.504967</td>\n",
       "      <td>-2.234167</td>\n",
       "      <td>...</td>\n",
       "      <td>2.585817</td>\n",
       "      <td>-5.291690</td>\n",
       "      <td>0.859364</td>\n",
       "      <td>0.423231</td>\n",
       "      <td>-0.506985</td>\n",
       "      <td>1.020052</td>\n",
       "      <td>-0.627751</td>\n",
       "      <td>-0.017753</td>\n",
       "      <td>0.280982</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.071805</td>\n",
       "      <td>-0.477943</td>\n",
       "      <td>-1.444444</td>\n",
       "      <td>-0.548657</td>\n",
       "      <td>0.010036</td>\n",
       "      <td>-0.582242</td>\n",
       "      <td>-0.042878</td>\n",
       "      <td>-0.247160</td>\n",
       "      <td>1.171923</td>\n",
       "      <td>-0.342382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077306</td>\n",
       "      <td>0.042858</td>\n",
       "      <td>0.390125</td>\n",
       "      <td>0.041569</td>\n",
       "      <td>0.598427</td>\n",
       "      <td>0.098803</td>\n",
       "      <td>0.979686</td>\n",
       "      <td>-0.093244</td>\n",
       "      <td>-0.065615</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.985294</td>\n",
       "      <td>-2.747472</td>\n",
       "      <td>1.194068</td>\n",
       "      <td>-0.003036</td>\n",
       "      <td>-1.151041</td>\n",
       "      <td>-0.263559</td>\n",
       "      <td>0.553500</td>\n",
       "      <td>0.635600</td>\n",
       "      <td>0.438545</td>\n",
       "      <td>-1.806488</td>\n",
       "      <td>...</td>\n",
       "      <td>1.345776</td>\n",
       "      <td>0.373760</td>\n",
       "      <td>-0.385777</td>\n",
       "      <td>1.197596</td>\n",
       "      <td>0.407229</td>\n",
       "      <td>0.008013</td>\n",
       "      <td>0.762362</td>\n",
       "      <td>-0.299024</td>\n",
       "      <td>-0.303929</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.479452</td>\n",
       "      <td>1.542874</td>\n",
       "      <td>0.290895</td>\n",
       "      <td>0.838142</td>\n",
       "      <td>-0.529290</td>\n",
       "      <td>-0.717661</td>\n",
       "      <td>0.484516</td>\n",
       "      <td>0.545092</td>\n",
       "      <td>-0.780767</td>\n",
       "      <td>0.324804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038397</td>\n",
       "      <td>0.116771</td>\n",
       "      <td>0.405560</td>\n",
       "      <td>-0.116453</td>\n",
       "      <td>0.541275</td>\n",
       "      <td>-0.216665</td>\n",
       "      <td>-0.415578</td>\n",
       "      <td>0.027126</td>\n",
       "      <td>-0.150347</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.281976</td>\n",
       "      <td>-0.309699</td>\n",
       "      <td>-2.162299</td>\n",
       "      <td>-0.851514</td>\n",
       "      <td>0.106167</td>\n",
       "      <td>-1.483888</td>\n",
       "      <td>1.930994</td>\n",
       "      <td>-0.843049</td>\n",
       "      <td>-1.249272</td>\n",
       "      <td>1.079608</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.875516</td>\n",
       "      <td>-0.004199</td>\n",
       "      <td>1.015108</td>\n",
       "      <td>-0.026748</td>\n",
       "      <td>0.077115</td>\n",
       "      <td>-1.468822</td>\n",
       "      <td>0.751700</td>\n",
       "      <td>0.496732</td>\n",
       "      <td>0.331001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.848212  2.384900  0.379573  1.048381 -0.845070  2.537837 -4.542983   \n",
       "1  2.071805 -0.477943 -1.444444 -0.548657  0.010036 -0.582242 -0.042878   \n",
       "2 -2.985294 -2.747472  1.194068 -0.003036 -1.151041 -0.263559  0.553500   \n",
       "3 -1.479452  1.542874  0.290895  0.838142 -0.529290 -0.717661  0.484516   \n",
       "4 -0.281976 -0.309699 -2.162299 -0.851514  0.106167 -1.483888  1.930994   \n",
       "\n",
       "          V8        V9       V10  ...       V20       V21       V22       V23  \\\n",
       "0 -10.201458 -1.504967 -2.234167  ...  2.585817 -5.291690  0.859364  0.423231   \n",
       "1  -0.247160  1.171923 -0.342382  ... -0.077306  0.042858  0.390125  0.041569   \n",
       "2   0.635600  0.438545 -1.806488  ...  1.345776  0.373760 -0.385777  1.197596   \n",
       "3   0.545092 -0.780767  0.324804  ...  0.038397  0.116771  0.405560 -0.116453   \n",
       "4  -0.843049 -1.249272  1.079608  ... -0.875516 -0.004199  1.015108 -0.026748   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  \n",
       "0 -0.506985  1.020052 -0.627751 -0.017753  0.280982      0  \n",
       "1  0.598427  0.098803  0.979686 -0.093244 -0.065615      0  \n",
       "2  0.407229  0.008013  0.762362 -0.299024 -0.303929      0  \n",
       "3  0.541275 -0.216665 -0.415578  0.027126 -0.150347      0  \n",
       "4  0.077115 -1.468822  0.751700  0.496732  0.331001      0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V1       0\n",
       "V2       0\n",
       "V3       0\n",
       "V4       0\n",
       "V5       0\n",
       "V6       0\n",
       "V7       0\n",
       "V8       0\n",
       "V9       0\n",
       "V10      0\n",
       "V11      0\n",
       "V12      0\n",
       "V13      0\n",
       "V14      0\n",
       "V15      0\n",
       "V16      0\n",
       "V17      0\n",
       "V18      0\n",
       "V19      0\n",
       "V20      0\n",
       "V21      0\n",
       "V22      0\n",
       "V23      0\n",
       "V24      0\n",
       "V25      0\n",
       "V26      0\n",
       "V27      0\n",
       "V28      0\n",
       "Class    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측치는 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28678, 29)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Count</th>\n",
       "      <th>Percent(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>28432</td>\n",
       "      <td>99.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>246</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target  Count  Percent(%)\n",
       "0       0  28432       99.14\n",
       "1       1    246        0.86"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = data['Class'].value_counts().to_frame().reset_index()\n",
    "tmp['Percent(%)'] = tmp[\"Class\"].apply(lambda x : round(100*float(x) / len(data), 2))\n",
    "tmp = tmp.rename(columns = {\"index\" : \"Target\", \"Class\" : \"Count\"})\n",
    "\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "총 28,678 건의 데이터 중 246건만이 사기 거래 데이터임을 알 수 있음. \n",
    "\n",
    "이는 사기 거래가 정상 거래에 비해 매우 적은 **'Highly unbalanced'**한 특징을 가진 데이터셋임.\n",
    "\n",
    "이 데이터를 예측 모델 및 분석의 기반으로 사용하면 오류가 많이 발생할 수 있으며 대부분의 트랜잭션이 부정 행위가 아니라고 '가정'하기 때문에 알고리즘이 지나치게 적합할 수 있음.\n",
    "\n",
    "따라서, 정확도를 기준으로 모델 평기지표를 사용하기보다는 `정밀도`, `재현율` 등의 지표를 개선하고자 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Engneering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.015438</td>\n",
       "      <td>0.053653</td>\n",
       "      <td>-0.046031</td>\n",
       "      <td>0.037348</td>\n",
       "      <td>-0.033724</td>\n",
       "      <td>-0.003299</td>\n",
       "      <td>-0.051054</td>\n",
       "      <td>0.006064</td>\n",
       "      <td>-0.018530</td>\n",
       "      <td>-0.041149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>-0.000656</td>\n",
       "      <td>-0.004800</td>\n",
       "      <td>-0.000897</td>\n",
       "      <td>-0.001989</td>\n",
       "      <td>-0.000765</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>0.008578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.031529</td>\n",
       "      <td>1.616186</td>\n",
       "      <td>1.758169</td>\n",
       "      <td>1.482109</td>\n",
       "      <td>1.486998</td>\n",
       "      <td>1.339259</td>\n",
       "      <td>1.454827</td>\n",
       "      <td>1.364342</td>\n",
       "      <td>1.134065</td>\n",
       "      <td>1.252593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.720307</td>\n",
       "      <td>0.847152</td>\n",
       "      <td>0.739469</td>\n",
       "      <td>0.593663</td>\n",
       "      <td>0.603349</td>\n",
       "      <td>0.517968</td>\n",
       "      <td>0.483852</td>\n",
       "      <td>0.397075</td>\n",
       "      <td>0.296736</td>\n",
       "      <td>0.092221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-30.552380</td>\n",
       "      <td>-42.172688</td>\n",
       "      <td>-31.103685</td>\n",
       "      <td>-5.560118</td>\n",
       "      <td>-42.147898</td>\n",
       "      <td>-21.929312</td>\n",
       "      <td>-41.506796</td>\n",
       "      <td>-39.267378</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>-24.403185</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.387122</td>\n",
       "      <td>-21.453736</td>\n",
       "      <td>-8.887017</td>\n",
       "      <td>-36.666000</td>\n",
       "      <td>-2.718024</td>\n",
       "      <td>-6.712624</td>\n",
       "      <td>-2.241620</td>\n",
       "      <td>-7.418878</td>\n",
       "      <td>-9.617915</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.916927</td>\n",
       "      <td>-0.575381</td>\n",
       "      <td>-0.899872</td>\n",
       "      <td>-0.843321</td>\n",
       "      <td>-0.714901</td>\n",
       "      <td>-0.763757</td>\n",
       "      <td>-0.568146</td>\n",
       "      <td>-0.206103</td>\n",
       "      <td>-0.661909</td>\n",
       "      <td>-0.543450</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.209678</td>\n",
       "      <td>-0.225520</td>\n",
       "      <td>-0.539244</td>\n",
       "      <td>-0.160583</td>\n",
       "      <td>-0.356047</td>\n",
       "      <td>-0.318619</td>\n",
       "      <td>-0.327343</td>\n",
       "      <td>-0.070558</td>\n",
       "      <td>-0.052189</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.075358</td>\n",
       "      <td>0.180610</td>\n",
       "      <td>-0.008844</td>\n",
       "      <td>-0.060040</td>\n",
       "      <td>-0.271363</td>\n",
       "      <td>0.036107</td>\n",
       "      <td>0.022463</td>\n",
       "      <td>-0.055095</td>\n",
       "      <td>-0.097390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062792</td>\n",
       "      <td>-0.028778</td>\n",
       "      <td>0.007302</td>\n",
       "      <td>-0.011199</td>\n",
       "      <td>0.040006</td>\n",
       "      <td>0.019770</td>\n",
       "      <td>-0.056260</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.011075</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.317461</td>\n",
       "      <td>0.806957</td>\n",
       "      <td>1.029928</td>\n",
       "      <td>0.771958</td>\n",
       "      <td>0.613328</td>\n",
       "      <td>0.397269</td>\n",
       "      <td>0.559409</td>\n",
       "      <td>0.329606</td>\n",
       "      <td>0.605704</td>\n",
       "      <td>0.460681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131199</td>\n",
       "      <td>0.184312</td>\n",
       "      <td>0.526358</td>\n",
       "      <td>0.146835</td>\n",
       "      <td>0.437146</td>\n",
       "      <td>0.352717</td>\n",
       "      <td>0.240713</td>\n",
       "      <td>0.091637</td>\n",
       "      <td>0.078911</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.399484</td>\n",
       "      <td>21.467203</td>\n",
       "      <td>4.069865</td>\n",
       "      <td>11.927512</td>\n",
       "      <td>32.911462</td>\n",
       "      <td>22.529298</td>\n",
       "      <td>36.677268</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>8.113152</td>\n",
       "      <td>15.236028</td>\n",
       "      <td>...</td>\n",
       "      <td>26.237391</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>8.361985</td>\n",
       "      <td>9.637187</td>\n",
       "      <td>3.948061</td>\n",
       "      <td>2.510401</td>\n",
       "      <td>3.122747</td>\n",
       "      <td>11.135740</td>\n",
       "      <td>14.929133</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 V1            V2            V3            V4            V5  \\\n",
       "count  28678.000000  28678.000000  28678.000000  28678.000000  28678.000000   \n",
       "mean      -0.015438      0.053653     -0.046031      0.037348     -0.033724   \n",
       "std        2.031529      1.616186      1.758169      1.482109      1.486998   \n",
       "min      -30.552380    -42.172688    -31.103685     -5.560118    -42.147898   \n",
       "25%       -0.916927     -0.575381     -0.899872     -0.843321     -0.714901   \n",
       "50%        0.020050      0.075358      0.180610     -0.008844     -0.060040   \n",
       "75%        1.317461      0.806957      1.029928      0.771958      0.613328   \n",
       "max        2.399484     21.467203      4.069865     11.927512     32.911462   \n",
       "\n",
       "                 V6            V7            V8            V9           V10  \\\n",
       "count  28678.000000  28678.000000  28678.000000  28678.000000  28678.000000   \n",
       "mean      -0.003299     -0.051054      0.006064     -0.018530     -0.041149   \n",
       "std        1.339259      1.454827      1.364342      1.134065      1.252593   \n",
       "min      -21.929312    -41.506796    -39.267378    -13.434066    -24.403185   \n",
       "25%       -0.763757     -0.568146     -0.206103     -0.661909     -0.543450   \n",
       "50%       -0.271363      0.036107      0.022463     -0.055095     -0.097390   \n",
       "75%        0.397269      0.559409      0.329606      0.605704      0.460681   \n",
       "max       22.529298     36.677268     20.007208      8.113152     15.236028   \n",
       "\n",
       "       ...           V20           V21           V22           V23  \\\n",
       "count  ...  28678.000000  28678.000000  28678.000000  28678.000000   \n",
       "mean   ...      0.002633      0.010289     -0.000656     -0.004800   \n",
       "std    ...      0.720307      0.847152      0.739469      0.593663   \n",
       "min    ...    -21.387122    -21.453736     -8.887017    -36.666000   \n",
       "25%    ...     -0.209678     -0.225520     -0.539244     -0.160583   \n",
       "50%    ...     -0.062792     -0.028778      0.007302     -0.011199   \n",
       "75%    ...      0.131199      0.184312      0.526358      0.146835   \n",
       "max    ...     26.237391     27.202839      8.361985      9.637187   \n",
       "\n",
       "                V24           V25           V26           V27           V28  \\\n",
       "count  28678.000000  28678.000000  28678.000000  28678.000000  28678.000000   \n",
       "mean      -0.000897     -0.001989     -0.000765      0.000948      0.001535   \n",
       "std        0.603349      0.517968      0.483852      0.397075      0.296736   \n",
       "min       -2.718024     -6.712624     -2.241620     -7.418878     -9.617915   \n",
       "25%       -0.356047     -0.318619     -0.327343     -0.070558     -0.052189   \n",
       "50%        0.040006      0.019770     -0.056260      0.002049      0.011075   \n",
       "75%        0.437146      0.352717      0.240713      0.091637      0.078911   \n",
       "max        3.948061      2.510401      3.122747     11.135740     14.929133   \n",
       "\n",
       "              Class  \n",
       "count  28678.000000  \n",
       "mean       0.008578  \n",
       "std        0.092221  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비식별화 된 개인정보들의 분포가 일정하지 않음. \n",
    "\n",
    "따라서 scaling이 필요하며 Minmax Scaler를 이용함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.iloc[:, :-1]\n",
    "target = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "s_features = pd.DataFrame(scaler.fit_transform(features), columns = features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.926714</td>\n",
       "      <td>0.663520</td>\n",
       "      <td>0.882983</td>\n",
       "      <td>0.320081</td>\n",
       "      <td>0.561078</td>\n",
       "      <td>0.493178</td>\n",
       "      <td>0.530233</td>\n",
       "      <td>0.662568</td>\n",
       "      <td>0.622611</td>\n",
       "      <td>0.614594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469792</td>\n",
       "      <td>0.449133</td>\n",
       "      <td>0.441133</td>\n",
       "      <td>0.515181</td>\n",
       "      <td>0.791764</td>\n",
       "      <td>0.407605</td>\n",
       "      <td>0.727596</td>\n",
       "      <td>0.417730</td>\n",
       "      <td>0.399891</td>\n",
       "      <td>0.391878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.061651</td>\n",
       "      <td>0.025396</td>\n",
       "      <td>0.049986</td>\n",
       "      <td>0.084752</td>\n",
       "      <td>0.019811</td>\n",
       "      <td>0.030124</td>\n",
       "      <td>0.018608</td>\n",
       "      <td>0.023017</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084024</td>\n",
       "      <td>0.015125</td>\n",
       "      <td>0.017411</td>\n",
       "      <td>0.042870</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.090510</td>\n",
       "      <td>0.056160</td>\n",
       "      <td>0.090197</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.012088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.899356</td>\n",
       "      <td>0.653636</td>\n",
       "      <td>0.858708</td>\n",
       "      <td>0.269722</td>\n",
       "      <td>0.552003</td>\n",
       "      <td>0.476073</td>\n",
       "      <td>0.523619</td>\n",
       "      <td>0.658989</td>\n",
       "      <td>0.592752</td>\n",
       "      <td>0.601923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422444</td>\n",
       "      <td>0.444675</td>\n",
       "      <td>0.436287</td>\n",
       "      <td>0.483957</td>\n",
       "      <td>0.788400</td>\n",
       "      <td>0.354327</td>\n",
       "      <td>0.693265</td>\n",
       "      <td>0.356851</td>\n",
       "      <td>0.396037</td>\n",
       "      <td>0.389689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.927791</td>\n",
       "      <td>0.663861</td>\n",
       "      <td>0.889427</td>\n",
       "      <td>0.317440</td>\n",
       "      <td>0.560728</td>\n",
       "      <td>0.487149</td>\n",
       "      <td>0.531347</td>\n",
       "      <td>0.662845</td>\n",
       "      <td>0.620914</td>\n",
       "      <td>0.613176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469277</td>\n",
       "      <td>0.447760</td>\n",
       "      <td>0.440330</td>\n",
       "      <td>0.515643</td>\n",
       "      <td>0.791626</td>\n",
       "      <td>0.413741</td>\n",
       "      <td>0.729955</td>\n",
       "      <td>0.407385</td>\n",
       "      <td>0.399950</td>\n",
       "      <td>0.392267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.967164</td>\n",
       "      <td>0.675357</td>\n",
       "      <td>0.913573</td>\n",
       "      <td>0.362089</td>\n",
       "      <td>0.569699</td>\n",
       "      <td>0.502188</td>\n",
       "      <td>0.538041</td>\n",
       "      <td>0.668026</td>\n",
       "      <td>0.651582</td>\n",
       "      <td>0.627254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516566</td>\n",
       "      <td>0.451833</td>\n",
       "      <td>0.444710</td>\n",
       "      <td>0.545734</td>\n",
       "      <td>0.795039</td>\n",
       "      <td>0.473317</td>\n",
       "      <td>0.766055</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>0.404779</td>\n",
       "      <td>0.395030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 V1            V2            V3            V4            V5  \\\n",
       "count  28678.000000  28678.000000  28678.000000  28678.000000  28678.000000   \n",
       "mean       0.926714      0.663520      0.882983      0.320081      0.561078   \n",
       "std        0.061651      0.025396      0.049986      0.084752      0.019811   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.899356      0.653636      0.858708      0.269722      0.552003   \n",
       "50%        0.927791      0.663861      0.889427      0.317440      0.560728   \n",
       "75%        0.967164      0.675357      0.913573      0.362089      0.569699   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                 V6            V7            V8            V9           V10  \\\n",
       "count  28678.000000  28678.000000  28678.000000  28678.000000  28678.000000   \n",
       "mean       0.493178      0.530233      0.662568      0.622611      0.614594   \n",
       "std        0.030124      0.018608      0.023017      0.052632      0.031600   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.476073      0.523619      0.658989      0.592752      0.601923   \n",
       "50%        0.487149      0.531347      0.662845      0.620914      0.613176   \n",
       "75%        0.502188      0.538041      0.668026      0.651582      0.627254   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...           V19           V20           V21           V22  \\\n",
       "count  ...  28678.000000  28678.000000  28678.000000  28678.000000   \n",
       "mean   ...      0.469792      0.449133      0.441133      0.515181   \n",
       "std    ...      0.084024      0.015125      0.017411      0.042870   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.422444      0.444675      0.436287      0.483957   \n",
       "50%    ...      0.469277      0.447760      0.440330      0.515643   \n",
       "75%    ...      0.516566      0.451833      0.444710      0.545734   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                V23           V24           V25           V26           V27  \\\n",
       "count  28678.000000  28678.000000  28678.000000  28678.000000  28678.000000   \n",
       "mean       0.791764      0.407605      0.727596      0.417730      0.399891   \n",
       "std        0.012821      0.090510      0.056160      0.090197      0.021400   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.788400      0.354327      0.693265      0.356851      0.396037   \n",
       "50%        0.791626      0.413741      0.729955      0.407385      0.399950   \n",
       "75%        0.795039      0.473317      0.766055      0.462745      0.404779   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                V28  \n",
       "count  28678.000000  \n",
       "mean       0.391878  \n",
       "std        0.012088  \n",
       "min        0.000000  \n",
       "25%        0.389689  \n",
       "50%        0.392267  \n",
       "75%        0.395030  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22942, 28) (5736, 28) (22942,) (5736,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(s_features, target, test_size=0.2, random_state=10, stratify=target)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0 (non-fraud)</th>\n",
       "      <td>22745</td>\n",
       "      <td>5687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 (fraud)</th>\n",
       "      <td>197</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train  test\n",
       "0 (non-fraud)  22745  5687\n",
       "1 (fraud)        197    49"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([[sum(y_train == 0), sum(y_test == 0)], [sum(y_train ==1), sum(y_test == 1)]],\n",
    "            columns=['train','test'], index=['0 (non-fraud)', '1 (fraud)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "lr_pred = model.predict(X_test)\n",
    "lr_pred_proba = model.predict_proba(X_test)[:, -1].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차행렬, 정확도, 정밀도, 재현율을 한 번에 출력하는 함수\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion)\n",
    "    print('accuracy: {0:.4f}, precision: {1:.4f}, recall: {2:.4f}, f1: {3:.4f}, roc_auc: {4:.4f}'.format( accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[5686    1]\n",
      " [  17   32]]\n",
      "accuracy: 0.9969, precision: 0.9697, recall: 0.6531, f1: 0.7805, roc_auc: 0.9619\n"
     ]
    }
   ],
   "source": [
    "get_clf_eval(y_test, lr_pred, lr_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도와 정밀도는 높으나 재현율이 낮은 양상을 보임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, lr_pred).ravel()\n",
    "\n",
    "p = fn + tp\n",
    "n = tn + fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (tp + tn) / (p + n)\n",
    "errorRate = (fn + fp) / (p+n)\n",
    "recall = (tp) / p\n",
    "precision = tp/ (tp + fp)\n",
    "specificity =  tn / (tn + fp)\n",
    "fpr = fp / n\n",
    "f1 = f1_score(lr_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Accuracy(정확도)** : 전체 데이터 중에서 맞게 분류된 데이터의 비율\n",
    "* **Precision(정밀도)** : Positive로 예측한 데이터 중에 실제 positive인 비율\n",
    "* **Recall(재현율)** : 원래 positive 데이터에서 positive로 분류된 수\n",
    "* **f1_score** : Recall과 Precision의 조화평균\n",
    "* **roc_auc** :  AUC는 ROC 곡선 아래의 너비로 1에 가까울수록 좋은 모델임\n",
    "* **roc_curve** : 모델의 임계값을 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, model.decision_function(X_test))\n",
    "\n",
    "plt.plot(fpr, tpr, 'o-', label=\"Logistic Regression\") \n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot([1-specificity], [recall], 'ro', ms=10) # 현재 cutoff value 값 \n",
    "plt.xlabel('1-specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재의 cut-off value값은 최적점이 아님.\n",
    "\n",
    "`cut-off`는 판단의 가준이 되는 경계임. 이 데이터는 심한 불균형 data set이기에 암으로 예측되는 경우보다는 아닌 경우로 예측할 가능성이 훨씬 큼.\n",
    "\n",
    "그렇기에 logistic 함수로 구한 성공확률은 기존에 설정한 cut-off값보다 낮을 가능성이 큼. 때문에 우리는 cut-off 값을 낮추어 새로운 값으로 모델을 예측해야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능개선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cut-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적의 cut-off 값은 $(sensitivity) - (1 - specificity) = k$ 일때, 가장 큰 $k$로 정함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "optimal_pred = model.decision_function(X_test) > optimal_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, optimal_pred).ravel()\n",
    "\n",
    "p = fn + tp\n",
    "n = tn + fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9335774058577406\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp + tn) / (p + n)\n",
    "print(\"Accuracy : \", accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision :  0.10287081339712918\n"
     ]
    }
   ],
   "source": [
    "precision = tp / (tp + fp)\n",
    "print(\"precision : \", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cut off 조정 후 낮아진 것을 알 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall :  0.8775510204081632\n"
     ]
    }
   ],
   "source": [
    "recall = (tp) / p\n",
    "print('Recall : ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cut off 조정 후 높아진 것을 알 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specificity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specificity :  0.9340601371549148\n"
     ]
    }
   ],
   "source": [
    "specificity =  tn / (tn + fp)\n",
    "print(\"specificity : \", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, model.decision_function(X_test))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(fpr, tpr, 'o-', label=\"Logistic Regression\") \n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot([1-specificity], [recall], 'ro', ms=10) # 현재 cutoff value 값 \n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 개선 전 cut-off는 최적점이 아니었으나, 개선 후에는 최적점에 가깝게 위치가 바뀜\n",
    "* 재현율이 크게 향상했으나 정밀도가 크게 하락했기에 재현율과 정밀도 사이에는 trade-off관계에 있음을 알 수 있음. FP값이 커졌기에 재현율이 향상되고, FN값이 작아져 정밀도가 하락함.\n",
    "* 카드 사기 데이터셋은 심장병 예측 데이터 셋과 마찬가지로 재현율이 정밀도보다 중요한 지표임. 정상 거래(질병x)를 사기 거래(질병 O)라고 예측하면 다시 검토(검사)를 통해 해당 예측을 철회할 수 있으나 실제로 사기 거래(질병O)를 정상 거래(질병 x)로 판단하면 큰 손실을 입히기 때문임.\n",
    "* 따라서 cut-off 조정은 재현율이 크게 개선되었기 때문에 더 나은 방향으로 바뀌었다고 할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE 오버 샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 학습용 피처/레이블 데이터 세트:  (22942, 28) (22942,)\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (45490, 28) (45490,)\n",
      "SMOTE 적용 후 레이블 값 분포: \n",
      " 0    22745\n",
      "1    22745\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "\n",
    "X_train_over, y_train_over = smote.fit_resample(X_train, y_train)\n",
    "print('SMOTE 적용 전 학습용 피처/레이블 데이터 세트: ', X_train.shape, y_train.shape)\n",
    "print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트: ', X_train_over.shape, y_train_over.shape)\n",
    "print('SMOTE 적용 후 레이블 값 분포: \\n', pd.Series(y_train_over).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22745\n",
       "1      197\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SMOTE 적용 전 레이블 값 분포\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_over, y_train_over)\n",
    "lr_pred_over = model.predict(X_test)\n",
    "lr_pred_proba_over = model.predict_proba(X_test)[:, -1].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[5613   74]\n",
      " [   7   42]]\n",
      "accuracy: 0.9859, precision: 0.3621, recall: 0.8571, f1: 0.5091, roc_auc: 0.9696\n"
     ]
    }
   ],
   "source": [
    "get_clf_eval(y_test, lr_pred_over, lr_pred_proba_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE로 오버 샘플링된 데이터로 로지스틱 회귀를 사용해 학습할 경우 재현율이 0.8571로 증가하지만 정밀도가 0.362로 크게 감소함.\n",
    "\n",
    "이는 로지스틱 회귀 모델이 오버 샘플링으로 인해 실제 원본 데이터의 유형보다 너무 많은 class=1 데이터를 학습하면서 실제 테스트 데이터 세트에서 예측을 지나치게 class=1로 적용해 정밀도가 급격히 떨어짐."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Regression_과제3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
